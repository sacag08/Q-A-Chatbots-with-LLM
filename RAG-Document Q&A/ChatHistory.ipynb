{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\",groq_api_key = groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Sachit! It's nice to meet you. \\n\\nWhat subject are you studying? üìö  Are you working on any interesting projects right now? üòÑ  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 20, 'total_tokens': 59, 'completion_time': 0.070909091, 'prompt_time': 7.933e-05, 'queue_time': 0.014374877999999999, 'total_time': 0.070988421}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-005548bd-cb97-489e-bf10-969deb24740c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 39, 'total_tokens': 59})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi My name is Sachit and i am a student\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Sachit and that you are a student. üòä \\n\\nIs there anything else you'd like to tell me about yourself? I'm happy to chat! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 70, 'total_tokens': 112, 'completion_time': 0.076363636, 'prompt_time': 0.002265384, 'queue_time': 0.013001575999999999, 'total_time': 0.07862902}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2b11ff40-5a55-484a-8ba1-501d51b0b514-0', usage_metadata={'input_tokens': 70, 'output_tokens': 42, 'total_tokens': 112})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi my name is Sachit and i am a student\"),\n",
    "        AIMessage(content=\"Hello Sachit! It's nice to meet you.  \\n\\nWhat subject are you studying? What do you find most interesting about it? \\n\\n\"),\n",
    "        HumanMessage(content=\"Whats my name and what do i do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store= {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "responce = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi i am sachit,i am a student\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sachit! \\n\\nIt's nice to meet you. What are you studying? üòä  \\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sachit.  \\n\\nIs there anything else I can help you with? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 55, 'total_tokens': 78, 'completion_time': 0.041818182, 'prompt_time': 0.001840325, 'queue_time': 0.012491885, 'total_time': 0.043658507}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-aedd7e57-4f6e-4167-b288-2f2f6a0a3f2a-0', usage_metadata={'input_tokens': 55, 'output_tokens': 23, 'total_tokens': 78})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"whats my name?\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know! üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 13, 'total_tokens': 53, 'completion_time': 0.072727273, 'prompt_time': 8.1249e-05, 'queue_time': 0.014572508999999999, 'total_time': 0.072808522}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-73c26cd1-e839-499d-89fd-8540da1c036d-0', usage_metadata={'input_tokens': 13, 'output_tokens': 40, 'total_tokens': 53})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"whats my name?\")],\n",
    "        config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpfull assistance. Answer all question based on best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "        \n",
    "    ]\n",
    ")\n",
    "chain = promt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Sachit, it's nice to meet you! \\n\\nHow can I help you today? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 32, 'total_tokens': 58, 'completion_time': 0.047272727, 'prompt_time': 0.001029417, 'queue_time': 0.012922651, 'total_time': 0.048302144}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-55cbbd8c-ae72-486a-901a-cf5995521b12-0', usage_metadata={'input_tokens': 32, 'output_tokens': 26, 'total_tokens': 58})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Sachit\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and no way to know your name.  \\n\\nIf you'd like to tell me your name, I'm happy to know! üòä \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 29, 'total_tokens': 74, 'completion_time': 0.081818182, 'prompt_time': 0.00015098, 'queue_time': 0.013606178, 'total_time': 0.081969162}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-dfe4972a-ae63-49a5-a276-fd6b672c045e-0', usage_metadata={'input_tokens': 29, 'output_tokens': 45, 'total_tokens': 74})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"whats my name\")\n",
    "    ],\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpfull assistance. Answer all question based on best of your ability in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "        \n",
    "    ]\n",
    ")\n",
    "chain = promt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑‡•ç‡§£!  üòä  ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§®‡•á ‡§Æ‡•á‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡•Ä‡•§ ‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡•ô‡•Å‡§∂‡•Ä ‡§π‡•ã‡§ó‡•Ä‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è‡•§ \\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce = chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Krish\")],\"language\":\"Hindhi\"})\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑‡•ç‡§£!  ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§®‡•á ‡§Æ‡•Å‡§ù‡•á ‡§ö‡§æ‡§π‡§æ‡•§  \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•Å‡§õ ‡§≠‡•Ä ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡•Ç‡§Ç‡•§ \\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let wrap this with message history\n",
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")\n",
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "responce = with_message_history.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Krish\")],\"language\":\"Hindi\"},\n",
    "                                       config = config)\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•É‡§∑‡•ç‡§£ ‡§π‡•à, ‡§ú‡•à‡§∏‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§®‡•á ‡§ñ‡•Å‡§¶ ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§•‡§æ‡•§  üòä  \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")\n",
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "responce = with_message_history.invoke({\"messages\":[HumanMessage(content=\"Whatsmy name\")],\"language\":\"Hindi\"},\n",
    "                                       config = config)\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi may name is sachit', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='8', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no probelem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages # trim_messages help to how many tokens to send to model in history\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 90,\n",
    "    strategy = \"last\",\n",
    "    token_counter=model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you are a good assistant\"),\n",
    "    HumanMessage(\"hi may name is sachit\"),\n",
    "    AIMessage(\"Hi!\"),\n",
    "    HumanMessage(\"I like vanilla ice cream\"),\n",
    "    AIMessage(\"nice\"),\n",
    "    HumanMessage(\"whats 2+2\"),\n",
    "    AIMessage(\"8\"),\n",
    "    HumanMessage(\"thanks\"),\n",
    "    AIMessage(\"no probelem\"),\n",
    "    HumanMessage(\"having fun?\"),\n",
    "    AIMessage(\"No!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked: \"What is 2+2?\" \\n\\nAnd the answer is correct!  \\n\\n2 + 2 = 4 \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | promt \n",
    "    | model \n",
    ")\n",
    "responce = chain.invoke(\n",
    "    { \n",
    "    \"messages\": messages + [HumanMessage(content=\"What math probem did i ask and was the answer correct?\")],\n",
    "    \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets wrap it in message history\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key = \"messages\",\n",
    ")\n",
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"What is 2+2?\" \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Sachit! üòä  \\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what is my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
