{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\",groq_api_key = groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Sachit! It's nice to meet you. \\n\\nWhat subject are you studying? 📚  Are you working on any interesting projects right now? 😄  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 20, 'total_tokens': 59, 'completion_time': 0.070909091, 'prompt_time': 7.933e-05, 'queue_time': 0.014374877999999999, 'total_time': 0.070988421}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-005548bd-cb97-489e-bf10-969deb24740c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 39, 'total_tokens': 59})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi My name is Sachit and i am a student\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Sachit and that you are a student. 😊 \\n\\nIs there anything else you'd like to tell me about yourself? I'm happy to chat! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 70, 'total_tokens': 112, 'completion_time': 0.076363636, 'prompt_time': 0.002265384, 'queue_time': 0.013001575999999999, 'total_time': 0.07862902}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2b11ff40-5a55-484a-8ba1-501d51b0b514-0', usage_metadata={'input_tokens': 70, 'output_tokens': 42, 'total_tokens': 112})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi my name is Sachit and i am a student\"),\n",
    "        AIMessage(content=\"Hello Sachit! It's nice to meet you.  \\n\\nWhat subject are you studying? What do you find most interesting about it? \\n\\n\"),\n",
    "        HumanMessage(content=\"Whats my name and what do i do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store= {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "responce = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi i am sachit,i am a student\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sachit! \\n\\nIt's nice to meet you. What are you studying? 😊  \\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sachit.  \\n\\nIs there anything else I can help you with? 😊 \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 55, 'total_tokens': 78, 'completion_time': 0.041818182, 'prompt_time': 0.001840325, 'queue_time': 0.012491885, 'total_time': 0.043658507}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-aedd7e57-4f6e-4167-b288-2f2f6a0a3f2a-0', usage_metadata={'input_tokens': 55, 'output_tokens': 23, 'total_tokens': 78})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"whats my name?\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know! 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 13, 'total_tokens': 53, 'completion_time': 0.072727273, 'prompt_time': 8.1249e-05, 'queue_time': 0.014572508999999999, 'total_time': 0.072808522}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-73c26cd1-e839-499d-89fd-8540da1c036d-0', usage_metadata={'input_tokens': 13, 'output_tokens': 40, 'total_tokens': 53})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"whats my name?\")],\n",
    "        config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpfull assistance. Answer all question based on best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "        \n",
    "    ]\n",
    ")\n",
    "chain = promt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Sachit, it's nice to meet you! \\n\\nHow can I help you today? 😊  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 32, 'total_tokens': 58, 'completion_time': 0.047272727, 'prompt_time': 0.001029417, 'queue_time': 0.012922651, 'total_time': 0.048302144}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-55cbbd8c-ae72-486a-901a-cf5995521b12-0', usage_metadata={'input_tokens': 32, 'output_tokens': 26, 'total_tokens': 58})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Sachit\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and no way to know your name.  \\n\\nIf you'd like to tell me your name, I'm happy to know! 😊 \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 29, 'total_tokens': 74, 'completion_time': 0.081818182, 'prompt_time': 0.00015098, 'queue_time': 0.013606178, 'total_time': 0.081969162}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-dfe4972a-ae63-49a5-a276-fd6b672c045e-0', usage_metadata={'input_tokens': 29, 'output_tokens': 45, 'total_tokens': 74})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"whats my name\")\n",
    "    ],\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpfull assistance. Answer all question based on best of your ability in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "        \n",
    "    ]\n",
    ")\n",
    "chain = promt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते कृष्ण!  😊  मुझे बहुत खुशी है कि आपने मेसे बात की। मुझे आपकी मदद करने में बहुत ख़ुशी होगी। आप मुझसे कोई भी सवाल पूछ सकते हैं, मैं अपनी पूरी कोशिश करूँगा जवाब देने के लिए। \\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce = chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Krish\")],\"language\":\"Hindhi\"})\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते कृष्ण!  मुझे बहुत खुशी है कि आपने मुझे चाहा।  \\n\\nआप मुझसे कुछ भी पूछ सकते हैं, मैं अपनी पूरी कोशिश करूँगा कि आपकी मदद कर सकूं। \\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let wrap this with message history\n",
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")\n",
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "responce = with_message_history.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Krish\")],\"language\":\"Hindi\"},\n",
    "                                       config = config)\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आपका नाम कृष्ण है, जैसा कि आपने खुद मुझे बताया था।  😊  \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")\n",
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "responce = with_message_history.invoke({\"messages\":[HumanMessage(content=\"Whatsmy name\")],\"language\":\"Hindi\"},\n",
    "                                       config = config)\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi may name is sachit', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='8', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no probelem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages # trim_messages help to how many tokens to send to model in history\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 90,\n",
    "    strategy = \"last\",\n",
    "    token_counter=model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you are a good assistant\"),\n",
    "    HumanMessage(\"hi may name is sachit\"),\n",
    "    AIMessage(\"Hi!\"),\n",
    "    HumanMessage(\"I like vanilla ice cream\"),\n",
    "    AIMessage(\"nice\"),\n",
    "    HumanMessage(\"whats 2+2\"),\n",
    "    AIMessage(\"8\"),\n",
    "    HumanMessage(\"thanks\"),\n",
    "    AIMessage(\"no probelem\"),\n",
    "    HumanMessage(\"having fun?\"),\n",
    "    AIMessage(\"No!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked: \"What is 2+2?\" \\n\\nAnd the answer is correct!  \\n\\n2 + 2 = 4 \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | promt \n",
    "    | model \n",
    ")\n",
    "responce = chain.invoke(\n",
    "    { \n",
    "    \"messages\": messages + [HumanMessage(content=\"What math probem did i ask and was the answer correct?\")],\n",
    "    \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets wrap it in message history\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key = \"messages\",\n",
    ")\n",
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"What is 2+2?\" \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Sachit! 😊  \\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what is my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
